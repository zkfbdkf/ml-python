{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chminPark/ml-python/blob/master/%EC%8B%A4%EC%8A%B5_PretrainedModel%ED%99%9C%EC%9A%A9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6TV0MdKQBU5w",
        "outputId": "98aa08c9-6acb-4601-f21f-cc16596755d7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.1.0+cu118'"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Pytorch로 개발하기 위한 Library\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvM0McnQ8Mx8",
        "outputId": "b92a656c-9a45-49ed-951c-f8d83555554c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1nOUWByW6ifnd_P-Jgd4mbNkAT-jGzpWC\n",
            "To: /content/semiconductor_dataset.zip\n",
            "100% 10.3M/10.3M [00:00<00:00, 51.6MB/s]\n",
            "mkdir: cannot create directory ‘semicon’: File exists\n",
            "replace semicon/abnorm_1/1-4.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
          ]
        }
      ],
      "source": [
        "!gdown --id 1nOUWByW6ifnd_P-Jgd4mbNkAT-jGzpWC\n",
        "!mkdir 'semicon'\n",
        "!unzip -q semiconductor_dataset.zip -d semicon\n",
        "!rm semiconductor_dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dXEooJlWsRV"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import os\n",
        "import pandas as pd\n",
        "\"\"\"\n",
        "Args:\n",
        "  directory_string: 이미지가 저장되어 있는 폴더 Path\n",
        "  output_csv_name: csv 파일 이름\n",
        "Returns:\n",
        "  csv file\n",
        "\"\"\"\n",
        "def build_csv(directory_string, output_csv_name):\n",
        "\n",
        "    directory = directory_string\n",
        "    class_list = os.listdir(directory)\n",
        "    class_list.sort()\n",
        "\n",
        "\n",
        "    with open(output_csv_name, 'w', newline='') as csvfile:\n",
        "\n",
        "        ### 실습 : CSV 파일 Object 생성\n",
        "        writer = csv.writer(csvfile, delimiter=',')\n",
        "        ############################################\n",
        "        writer.writerow(['file_name', 'file_path', 'class_name', 'class_index']) # CSV의 column 이름을 지정\n",
        "\n",
        "        ###### 각 folder에 들어가서 각 이미지의 이름을 가져옴\n",
        "        for class_name in class_list:\n",
        "          class_path = os.path.join(directory, class_name)\n",
        "          file_list = os.listdir(class_path) # 해당 파일 내부의 이미지를 확보\n",
        "          for file_name in file_list:\n",
        "              file_path = os.path.join(directory, class_name, file_name) #concatenate class folder dir, class name and file name\n",
        "              writer.writerow([file_name, file_path, class_name, class_name.split(\"_\")[1]]) #write the file path and class name to the csv file\n",
        "        #############################\n",
        "\n",
        "    return\n",
        "\n",
        "train_folder = os.path.join(os.getcwd(), 'semicon')\n",
        "build_csv(train_folder, 'train.csv')\n",
        "train_df = pd.read_csv('train.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i837jqmdjrGV"
      },
      "source": [
        "# Custom데이터를 활용하기 위한 Dataset을 선언\n",
        "- pytorch의 `dataloader`를 이용하기 위해서는 `torch.utils.data.Dataset` 클래스를 상속한 클래스의 선언이 필요하다.\n",
        "- 클래스 내에 `__init__`, `__getitem__`, `__len__`의 3개의 메소드를 선언하여 오버라이드한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOUmcMyjYn-W"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class semiconductorDataset(Dataset): # inheritin from Dataset class\n",
        "\n",
        "    def __init__(self, csv_file, root_dir=\"\", transform=None):\n",
        "        self.annotation_df = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir # root directory of images, leave \"\" if using the image path column in the __getitem__ method\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.annotation_df) # return length (numer of rows) of the dataframe\n",
        "\n",
        "    ############ 실습 : annotation_df에 있는 이미지를 읽어 들어서, 변경한후\n",
        "    ############        읽어 들인 값을 return 하는 함수를 작성한다.\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        ##### Image 읽기\n",
        "        image_path = os.path.join(self.root_dir, self.annotation_df.iloc[idx, 1]) #use image path column (index = 1) in csv file\n",
        "        image = cv2.imread(image_path) # read image by cv2\n",
        "        #### 이미지를 Channel순서를 변경\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # convert from BGR to RGB for matplotlib\n",
        "        #### 이미지 Transform\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        #### 이미지에 대한 추가 정보 확인\n",
        "        class_name = self.annotation_df.iloc[idx, 2] # use class name column (index = 2) in csv file\n",
        "        class_index = self.annotation_df.iloc[idx, 3] # use class index column (index = 3) in csv file\n",
        "\n",
        "        return image, class_name, class_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aH1Zej7hLxxR"
      },
      "outputs": [],
      "source": [
        "# https://pytorch.org/vision/stable/auto_examples/plot_transforms.html#sphx-glr-auto-examples-plot-transforms-py\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(), # PIL Image를 Tensor로 변경\n",
        "    transforms.Resize((256,256), antialias=True), # 크기 변경\n",
        "    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)), # Normalize\n",
        "    # transforms.Grayscale(), # Gray Scale로 변경 /\n",
        "    transforms.RandomAdjustSharpness(sharpness_factor=2), # randomly adjusts the sharpness\n",
        "    transforms.RandomAutocontrast() # 임의로 Contrast변경\n",
        "])\n",
        "\n",
        "##### 실습 : train_dataset 선언\n",
        "train_dataset = semiconductorDataset(csv_file='train.csv', root_dir=\"\", transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghCR7igHNMG1"
      },
      "outputs": [],
      "source": [
        "# Image plotting function\n",
        "def img_plt(X_train, Y_train, n):\n",
        "  X_train_2d = X_train.reshape(X_train.shape[0], 256, 256)\n",
        "  fig, axes = plt.subplots(n, 10, figsize=(10,10))\n",
        "  for j in range(n):\n",
        "    for i in range(10):\n",
        "        ax = axes[j, i]\n",
        "        try:\n",
        "          ax.imshow(X_train_2d[Y_train==j][i], cmap='gray_r')\n",
        "          ax.axis('off')\n",
        "          if i == 0:\n",
        "            ax.set_title('Cluster: {}'.format(j))\n",
        "        except:\n",
        "          ax.axis('off')\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5pV5UK4kBiR"
      },
      "source": [
        "# Batch 단위 학습을 위한 DataLoader 선언\n",
        " - Dataset내부의 샘플들을 batch 크기로 추출\n",
        " - Batch Size는 1step에 들어간 데이터의 개수\n",
        " - Epoch 마다 데이터를 섞어(Shuffle) Overfitting을 방지\n",
        " - 병렬처리를 지원하여 데이터 검색 속도를 향상\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCTnlT1pRpSS",
        "outputId": "bd70051e-d46d-493e-bfeb-592b6b885ca7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([10, 3, 256, 256]) torch.Size([10])\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10])\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10])\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10])\n",
            "torch.Size([10, 3, 256, 256]) torch.Size([10])\n"
          ]
        }
      ],
      "source": [
        "#### 실습 : torch.utils.DataLoader를 이용하여 데이터를 load. Batch 크기를 10으로 한다.\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset,batch_size=10, shuffle=True, num_workers=2)\n",
        "\n",
        "for i, data in enumerate(train_dataloader):\n",
        "  images, class_name, labels = data\n",
        "  print(images.shape, labels.shape)\n",
        "\n",
        "  # 5번만 데이터를 load하고 멈춘다\n",
        "  if i > 3:\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhDfo_bXniHr"
      },
      "source": [
        "# VGG16를 Pretrained Model을 이용하여 학습한다.\n",
        "\n",
        "<img src=\"https://editor.analyticsvidhya.com/uploads/51271vgg.jpeg\" height=\"150px\" width=\"800px\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaTBk3ngEGz3",
        "outputId": "bdad390f-b42f-4652-8e98-73341391586a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace=True)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "from torchvision import models\n",
        "import torch\n",
        "\n",
        "vgg16_pretrained = models.vgg16(weights='VGG16_Weights.IMAGENET1K_V1')\n",
        "\n",
        "print(vgg16_pretrained)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6G3HkzGEGek",
        "outputId": "5bea6fd7-6de0-4cf0-c3eb-a210ec36bf19"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "  (1): ReLU(inplace=True)\n",
              "  (2): Dropout(p=0.5, inplace=False)\n",
              "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "  (4): ReLU(inplace=True)\n",
              "  (5): Dropout(p=0.5, inplace=False)\n",
              "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 최종 결과가 1000개로 나온다. 우리의 데이터는 11개의 class로 변경해야 한다.\n",
        "vgg16_pretrained.classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25nahJb2EF75",
        "outputId": "e00e3b51-56dd-4cb5-87b8-d1a09315fd7e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Linear(in_features=4096, out_features=1000, bias=True)"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vgg16_pretrained.classifier[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKvbnW-bGKL4"
      },
      "outputs": [],
      "source": [
        "vgg16_pretrained.classifier[-1] = nn.Linear(in_features=4096, out_features=11)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZ7YDxOQGPxY",
        "outputId": "ef70be51-e325-4f97-ac05-c434a7d72463"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "  (1): ReLU(inplace=True)\n",
              "  (2): Dropout(p=0.5, inplace=False)\n",
              "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "  (4): ReLU(inplace=True)\n",
              "  (5): Dropout(p=0.5, inplace=False)\n",
              "  (6): Linear(in_features=4096, out_features=11, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 변경된 것을 확인할 수 있다\n",
        "vgg16_pretrained.classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHya_ZR3vj0I"
      },
      "outputs": [],
      "source": [
        "def train(model, data_loader, criterion, optimizer, n_epoch):\n",
        "\n",
        "  model.train() #\n",
        "  for epoch in range(n_epoch):\n",
        "    running_loss = 0\n",
        "    ### 실습 : Custom dataloader 에서 값을 가져온다\n",
        "    for i, (images, _, labels) in enumerate(data_loader):\n",
        "      images, labels = images.cuda(), labels.cuda()\n",
        "      outputs = model(images)\n",
        "      loss = criterion(outputs, labels)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      running_loss += loss.item()\n",
        "      if (i + 1) % 100 == 0:\n",
        "        print('iteration: [{}/{}]'.format(i + 1, len(data_loader)))\n",
        "\n",
        "    print('Epoch {}, loss = {:.3f}'.format(epoch + 1, running_loss/len(data_loader)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uaHXeaKGjQU"
      },
      "outputs": [],
      "source": [
        "def eval(model, data_loader):\n",
        "\n",
        "  model.eval()\n",
        "  total = 0\n",
        "  correct = 0\n",
        "\n",
        "  preds = []\n",
        "  trues = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    ### 실습 : Custom dataloader 에서 값을 가져온다\n",
        "    for images, _,  labels in data_loader:\n",
        "      images, labels = images.cuda(), labels.cuda()\n",
        "      outputs = model(images)\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "      preds.append(predicted.detach().cpu().numpy())\n",
        "      trues.append(labels.detach().cpu().numpy())\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "\n",
        "  print('Test Accuracy: {}%'.format(accuracy))\n",
        "  return preds, trues\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLI00mauwDyZ"
      },
      "outputs": [],
      "source": [
        "def reset_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYtKeoevHOra",
        "outputId": "59509172-702a-45c3-926c-f6345dceb4aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 8.080808080808081%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        18\n",
            "           1       0.00      0.00      0.00        18\n",
            "           2       0.00      0.00      0.00        19\n",
            "           3       0.00      0.00      0.00        17\n",
            "           4       0.00      0.00      0.00        15\n",
            "           5       0.00      0.00      0.00        18\n",
            "           6       0.00      0.00      0.00        18\n",
            "           7       0.08      0.88      0.15        17\n",
            "           8       0.00      0.00      0.00        16\n",
            "           9       0.00      0.00      0.00        17\n",
            "          10       0.00      0.00      0.00        17\n",
            "\n",
            "    accuracy                           0.08       190\n",
            "   macro avg       0.01      0.08      0.01       190\n",
            "weighted avg       0.01      0.08      0.01       190\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# 학습 전에는 ImageNet의 정보를 이용하여 성능이 좋지 않음\n",
        "vgg16 = vgg16_pretrained.to(\"gpu\")\n",
        "preds, trues = eval(vgg16, train_dataloader)\n",
        "prediction_label = np.stack(preds[0:-1]).flatten()\n",
        "train_labels = np.stack(trues[0:-1]).flatten()\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(train_labels, prediction_label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "t85o-4CZve4T",
        "outputId": "5e2c8ba2-4ebc-442d-b375-e2abcbfb8848"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, loss = 2.187\n",
            "Epoch 2, loss = 0.834\n",
            "Epoch 3, loss = 0.147\n",
            "Epoch 4, loss = 0.021\n",
            "Epoch 5, loss = 0.009\n"
          ]
        }
      ],
      "source": [
        "reset_seed(2020)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "vgg16 = vgg16_pretrained #.to(\"cuda\")\n",
        "optimizer = optim.Adam(params=vgg16.parameters(), lr=0.00003)\n",
        "\n",
        "train(vgg16, train_dataloader, criterion, optimizer, n_epoch=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d4AUYGHJzQ6"
      },
      "source": [
        "# 정확도를 평가해 봅시다\n",
        "* 데이터가 너무 적어서 평가 데이터에 대한 정확도를 봅니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdj0G1XrrBkv"
      },
      "outputs": [],
      "source": [
        "preds, trues = eval(vgg16, train_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EITSxg8FGwP2"
      },
      "outputs": [],
      "source": [
        "prediction_label = np.stack(preds[0:-1]).flatten()\n",
        "train_labels = np.stack(trues[0:-1]).flatten()\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(train_labels, prediction_label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlfX4s6PHE08"
      },
      "outputs": [],
      "source": [
        "import torchvision.utils as utils\n",
        "\n",
        "# visualize the filters of the first CNN layer\n",
        "for i, w in enumerate(vgg16.parameters()):\n",
        "    w = w.data.cpu()\n",
        "    print(w.shape)\n",
        "    break\n",
        "\n",
        "# normalize weights\n",
        "min_w = torch.min(w)\n",
        "w1 = (-1/(2 * min_w)) * w + 0.5\n",
        "\n",
        "# make grid to display it\n",
        "grid_size = len(w1)\n",
        "x_grid = [w1[i] for i in range(grid_size)]\n",
        "x_grid = utils.make_grid(x_grid, nrow=8, padding=1)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "x_grid = x_grid.reshape(x_grid.shape[1], x_grid.shape[2], -1)\n",
        "plt.imshow(x_grid, cmap='gray_r')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WW3YT2amVrK6"
      },
      "source": [
        "# Visualize 해보겠습니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6T6t3FyLmws"
      },
      "outputs": [],
      "source": [
        "prediction_label = np.stack(preds[0:-1]).flatten()\n",
        "train_labels = np.stack(trues[0:-1]).flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WW-zeNcmIVmk"
      },
      "outputs": [],
      "source": [
        "idx_diff = np.where(train_labels != prediction_label)\n",
        "labels_diff = train_labels[idx_diff]\n",
        "predicted_diff = prediction_label[idx_diff]\n",
        "\n",
        "\n",
        "for t, p in zip(labels_diff, predicted_diff):\n",
        "  print(f\"정답 Label은 {t}, 예측 Label은 {p}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMtnCACjKKQL"
      },
      "outputs": [],
      "source": [
        "## 실습 : 전체 데이터를 한번에 가져오고, 이 결과를 기반으로 Report출력\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                               batch_size=len(train_dataset),\n",
        "                                               shuffle=False, num_workers=1)\n",
        "\n",
        "labels, predicted,images, names = None, None, None, None\n",
        "with torch.no_grad():\n",
        "  for images, names,  labels in train_dataloader:\n",
        "    continue\n",
        "\n",
        "names = np.array(list(names))\n",
        "\n",
        "print(images.shape, np.shape(names), labels.shape)\n",
        "\n",
        "\n",
        "images = images.squeeze()\n",
        "print(images.shape)\n",
        "\n",
        "#images = images.view(images.shape[0], -1)\n",
        "#images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHG6U_ttWJWn"
      },
      "outputs": [],
      "source": [
        "### 실습 : label 이 0인 이미지 중 5개만 추려서 출력해 봅시다\n",
        "target_index = np.where(labels == 0)[0]\n",
        "random_idx = np.random.choice(target_index, 2)\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, idx in enumerate(random_idx):\n",
        "\n",
        "  plt.subplot(1, 2, i+1)\n",
        "  plt.imshow(images[idx].reshape(256,256,3), cmap='gray_r')\n",
        "  plt.title('Digit : {} '.format(names[idx]), fontsize=14)\n",
        "  plt.xticks([]); plt.yticks([])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slT5q4HWOkKL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}