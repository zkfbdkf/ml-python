{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chminPark/ml-python/blob/master/VGG%EA%B8%B0%EB%B0%98_%EA%B8%B0%EB%B0%98%EB%B6%84%EB%A5%98_earlyStop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pytorch로 개발하기 위한 Library\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "torch.__version__"
      ],
      "metadata": {
        "id": "ADistk3mqNCK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "68914fe9-b963-4b9f-e8c8-57e9a235859d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0+cu118'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1L3aXv9A2bn8G9orLqjVWOE_1OY4ycdjs\n",
        "!mkdir 'chip_data'\n",
        "!unzip -q chip_data.zip -d chip_data\n",
        "!rm chip_data.zip"
      ],
      "metadata": {
        "id": "fvM0McnQ8Mx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import os\n",
        "import pandas as pd\n",
        "\"\"\"\n",
        "Args:\n",
        "  directory_string: 이미지가 저장되어 있는 폴더 Path\n",
        "  output_csv_name: csv 파일 이름\n",
        "Returns:\n",
        "  csv file\n",
        "\"\"\"\n",
        "dict_map = {\n",
        "        'crack, scratch, stamp' : 1,\n",
        "        'particle' : 2,\n",
        "        'titled' : 3,\n",
        "        \"와이어끊어짐\" : 4,\n",
        "        \"정상\": 0\n",
        "    }\n",
        "\n",
        "def build_csv(directory_string, output_csv_name):\n",
        "\n",
        "    directory = directory_string\n",
        "    class_list = os.listdir(directory)\n",
        "    class_list.sort()\n",
        "\n",
        "\n",
        "    with open(output_csv_name, 'w', newline='') as csvfile:\n",
        "\n",
        "        ### 실습 : CSV 파일 Object 생성\n",
        "        writer = csv.writer(csvfile, delimiter=',')\n",
        "        ############################################\n",
        "        writer.writerow(['file_name', 'file_path', 'class_name', 'class_index']) # CSV의 column 이름을 지정\n",
        "\n",
        "        ###### 각 folder에 들어가서 각 이미지의 이름을 가져옴\n",
        "        for class_name in class_list:\n",
        "          class_path = os.path.join(directory, class_name)\n",
        "          file_list = os.listdir(class_path) # 해당 파일 내부의 이미지를 확보\n",
        "          for file_name in file_list:\n",
        "              file_path = os.path.join(directory, class_name, file_name) #concatenate class folder dir, class name and file name\n",
        "              writer.writerow([file_name, file_path, class_name, dict_map[class_name]]) #write the file path and class name to the csv file\n",
        "        #############################\n",
        "\n",
        "    return\n",
        "\n",
        "train_folder = os.path.join(os.getcwd(), 'chip_data')\n",
        "build_csv(train_folder, 'train.csv')\n",
        "all_df = pd.read_csv('train.csv')\n"
      ],
      "metadata": {
        "id": "5dXEooJlWsRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_df"
      ],
      "metadata": {
        "id": "P8HvlmwipUpj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "outputId": "8b9fce1c-108e-49be-c964-65f167a87642"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   file_name  \\\n",
              "0    Sat Nov 25 13-03-11.jpg   \n",
              "1    Sat Nov 25 15-21-25.jpg   \n",
              "2    Sat Nov 25 13-04-11.jpg   \n",
              "3    Sat Nov 25 15-23-04.jpg   \n",
              "4    Sat Nov 25 13-26-50.jpg   \n",
              "..                       ...   \n",
              "850  Sat Nov 25 13-05-41.jpg   \n",
              "851  Sat Nov 25 13-44-18.jpg   \n",
              "852  Sat Nov 25 13-33-18.jpg   \n",
              "853  Sat Nov 25 14-05-47.jpg   \n",
              "854  Sat Nov 25 14-13-08.jpg   \n",
              "\n",
              "                                             file_path             class_name  \\\n",
              "0    /content/chip_data/crack, scratch, stamp/Sat N...  crack, scratch, stamp   \n",
              "1    /content/chip_data/crack, scratch, stamp/Sat N...  crack, scratch, stamp   \n",
              "2    /content/chip_data/crack, scratch, stamp/Sat N...  crack, scratch, stamp   \n",
              "3    /content/chip_data/crack, scratch, stamp/Sat N...  crack, scratch, stamp   \n",
              "4    /content/chip_data/crack, scratch, stamp/Sat N...  crack, scratch, stamp   \n",
              "..                                                 ...                    ...   \n",
              "850      /content/chip_data/정상/Sat Nov 25 13-05-41.jpg                     정상   \n",
              "851      /content/chip_data/정상/Sat Nov 25 13-44-18.jpg                     정상   \n",
              "852      /content/chip_data/정상/Sat Nov 25 13-33-18.jpg                     정상   \n",
              "853      /content/chip_data/정상/Sat Nov 25 14-05-47.jpg                     정상   \n",
              "854      /content/chip_data/정상/Sat Nov 25 14-13-08.jpg                     정상   \n",
              "\n",
              "     class_index  \n",
              "0              1  \n",
              "1              1  \n",
              "2              1  \n",
              "3              1  \n",
              "4              1  \n",
              "..           ...  \n",
              "850            0  \n",
              "851            0  \n",
              "852            0  \n",
              "853            0  \n",
              "854            0  \n",
              "\n",
              "[855 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-491e2a03-28b6-43f6-b93b-1e542141dab1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>file_path</th>\n",
              "      <th>class_name</th>\n",
              "      <th>class_index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sat Nov 25 13-03-11.jpg</td>\n",
              "      <td>/content/chip_data/crack, scratch, stamp/Sat N...</td>\n",
              "      <td>crack, scratch, stamp</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sat Nov 25 15-21-25.jpg</td>\n",
              "      <td>/content/chip_data/crack, scratch, stamp/Sat N...</td>\n",
              "      <td>crack, scratch, stamp</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sat Nov 25 13-04-11.jpg</td>\n",
              "      <td>/content/chip_data/crack, scratch, stamp/Sat N...</td>\n",
              "      <td>crack, scratch, stamp</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sat Nov 25 15-23-04.jpg</td>\n",
              "      <td>/content/chip_data/crack, scratch, stamp/Sat N...</td>\n",
              "      <td>crack, scratch, stamp</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sat Nov 25 13-26-50.jpg</td>\n",
              "      <td>/content/chip_data/crack, scratch, stamp/Sat N...</td>\n",
              "      <td>crack, scratch, stamp</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>850</th>\n",
              "      <td>Sat Nov 25 13-05-41.jpg</td>\n",
              "      <td>/content/chip_data/정상/Sat Nov 25 13-05-41.jpg</td>\n",
              "      <td>정상</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>851</th>\n",
              "      <td>Sat Nov 25 13-44-18.jpg</td>\n",
              "      <td>/content/chip_data/정상/Sat Nov 25 13-44-18.jpg</td>\n",
              "      <td>정상</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>852</th>\n",
              "      <td>Sat Nov 25 13-33-18.jpg</td>\n",
              "      <td>/content/chip_data/정상/Sat Nov 25 13-33-18.jpg</td>\n",
              "      <td>정상</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>853</th>\n",
              "      <td>Sat Nov 25 14-05-47.jpg</td>\n",
              "      <td>/content/chip_data/정상/Sat Nov 25 14-05-47.jpg</td>\n",
              "      <td>정상</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>854</th>\n",
              "      <td>Sat Nov 25 14-13-08.jpg</td>\n",
              "      <td>/content/chip_data/정상/Sat Nov 25 14-13-08.jpg</td>\n",
              "      <td>정상</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>855 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-491e2a03-28b6-43f6-b93b-1e542141dab1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-491e2a03-28b6-43f6-b93b-1e542141dab1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-491e2a03-28b6-43f6-b93b-1e542141dab1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-dbcf0ae7-170c-4e8f-bcc1-fefaef7bdf0c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dbcf0ae7-170c-4e8f-bcc1-fefaef7bdf0c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-dbcf0ae7-170c-4e8f-bcc1-fefaef7bdf0c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_df['class_index'].unique()"
      ],
      "metadata": {
        "id": "kanI8L3rdS2_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2579b53b-02e5-47d3-e7b5-7535893fafe0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3, 4, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(all_df, test_size=0.2, random_state=42, shuffle=True)"
      ],
      "metadata": {
        "id": "Q5CcMwA2fDtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['class_index'].value_counts(), test['class_index'].value_counts()"
      ],
      "metadata": {
        "id": "KThOxNbof1GO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e318d5c1-66fd-436a-a2bc-5ef82184f225"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0    369\n",
              " 1     99\n",
              " 2     80\n",
              " 4     79\n",
              " 3     57\n",
              " Name: class_index, dtype: int64,\n",
              " 0    88\n",
              " 1    28\n",
              " 4    22\n",
              " 3    18\n",
              " 2    15\n",
              " Name: class_index, dtype: int64)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(all_df, test_size=0.2, random_state=42, shuffle=True, stratify=all_df['class_index'])\n",
        "train['class_index'].value_counts(), test['class_index'].value_counts()"
      ],
      "metadata": {
        "id": "09PRNu9jf9v9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41ae0816-459d-4907-90de-f577c2700ad6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0    365\n",
              " 1    102\n",
              " 4     81\n",
              " 2     76\n",
              " 3     60\n",
              " Name: class_index, dtype: int64,\n",
              " 0    92\n",
              " 1    25\n",
              " 4    20\n",
              " 2    19\n",
              " 3    15\n",
              " Name: class_index, dtype: int64)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save df to csv\n",
        "train.to_csv(\"train.csv\", index=0)\n",
        "test.to_csv(\"test.csv\", index=0)"
      ],
      "metadata": {
        "id": "C8NZzi2QgfcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_csv(\"train.csv\")"
      ],
      "metadata": {
        "id": "P8_mGHHyg_yU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "outputId": "1823f000-12d0-4dbb-815b-e1846fc1bc01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   file_name  \\\n",
              "0    Sat Nov 25 15-15-14.jpg   \n",
              "1    Sat Nov 25 15-38-38.jpg   \n",
              "2    Sat Nov 25 14-16-48.jpg   \n",
              "3    Sat Nov 25 13-33-27.jpg   \n",
              "4    Sat Nov 25 14-05-49.jpg   \n",
              "..                       ...   \n",
              "679  Sat Nov 25 14-13-03.jpg   \n",
              "680  Sat Nov 25 15-03-38.jpg   \n",
              "681  Sat Nov 25 15-35-50.jpg   \n",
              "682  Sat Nov 25 15-22-50.jpg   \n",
              "683  Sat Nov 25 15-36-51.jpg   \n",
              "\n",
              "                                             file_path             class_name  \\\n",
              "0    /content/chip_data/와이어끊어짐/Sat Nov 25 15-15-14.jpg                 와이어끊어짐   \n",
              "1    /content/chip_data/particle/Sat Nov 25 15-38-3...               particle   \n",
              "2        /content/chip_data/정상/Sat Nov 25 14-16-48.jpg                     정상   \n",
              "3    /content/chip_data/crack, scratch, stamp/Sat N...  crack, scratch, stamp   \n",
              "4        /content/chip_data/정상/Sat Nov 25 14-05-49.jpg                     정상   \n",
              "..                                                 ...                    ...   \n",
              "679      /content/chip_data/정상/Sat Nov 25 14-13-03.jpg                     정상   \n",
              "680  /content/chip_data/와이어끊어짐/Sat Nov 25 15-03-38.jpg                 와이어끊어짐   \n",
              "681  /content/chip_data/particle/Sat Nov 25 15-35-5...               particle   \n",
              "682  /content/chip_data/crack, scratch, stamp/Sat N...  crack, scratch, stamp   \n",
              "683  /content/chip_data/particle/Sat Nov 25 15-36-5...               particle   \n",
              "\n",
              "     class_index  \n",
              "0              4  \n",
              "1              2  \n",
              "2              0  \n",
              "3              1  \n",
              "4              0  \n",
              "..           ...  \n",
              "679            0  \n",
              "680            4  \n",
              "681            2  \n",
              "682            1  \n",
              "683            2  \n",
              "\n",
              "[684 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-11afa1da-3d7f-4cc1-b591-5e34a975c271\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>file_path</th>\n",
              "      <th>class_name</th>\n",
              "      <th>class_index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sat Nov 25 15-15-14.jpg</td>\n",
              "      <td>/content/chip_data/와이어끊어짐/Sat Nov 25 15-15-14.jpg</td>\n",
              "      <td>와이어끊어짐</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sat Nov 25 15-38-38.jpg</td>\n",
              "      <td>/content/chip_data/particle/Sat Nov 25 15-38-3...</td>\n",
              "      <td>particle</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sat Nov 25 14-16-48.jpg</td>\n",
              "      <td>/content/chip_data/정상/Sat Nov 25 14-16-48.jpg</td>\n",
              "      <td>정상</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sat Nov 25 13-33-27.jpg</td>\n",
              "      <td>/content/chip_data/crack, scratch, stamp/Sat N...</td>\n",
              "      <td>crack, scratch, stamp</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sat Nov 25 14-05-49.jpg</td>\n",
              "      <td>/content/chip_data/정상/Sat Nov 25 14-05-49.jpg</td>\n",
              "      <td>정상</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>679</th>\n",
              "      <td>Sat Nov 25 14-13-03.jpg</td>\n",
              "      <td>/content/chip_data/정상/Sat Nov 25 14-13-03.jpg</td>\n",
              "      <td>정상</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>680</th>\n",
              "      <td>Sat Nov 25 15-03-38.jpg</td>\n",
              "      <td>/content/chip_data/와이어끊어짐/Sat Nov 25 15-03-38.jpg</td>\n",
              "      <td>와이어끊어짐</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>681</th>\n",
              "      <td>Sat Nov 25 15-35-50.jpg</td>\n",
              "      <td>/content/chip_data/particle/Sat Nov 25 15-35-5...</td>\n",
              "      <td>particle</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>682</th>\n",
              "      <td>Sat Nov 25 15-22-50.jpg</td>\n",
              "      <td>/content/chip_data/crack, scratch, stamp/Sat N...</td>\n",
              "      <td>crack, scratch, stamp</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>683</th>\n",
              "      <td>Sat Nov 25 15-36-51.jpg</td>\n",
              "      <td>/content/chip_data/particle/Sat Nov 25 15-36-5...</td>\n",
              "      <td>particle</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>684 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-11afa1da-3d7f-4cc1-b591-5e34a975c271')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-11afa1da-3d7f-4cc1-b591-5e34a975c271 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-11afa1da-3d7f-4cc1-b591-5e34a975c271');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-052b7bb4-7c08-480b-9d76-06f1e1f58e52\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-052b7bb4-7c08-480b-9d76-06f1e1f58e52')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-052b7bb4-7c08-480b-9d76-06f1e1f58e52 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom데이터를 활용하기 위한 Dataset을 선언\n",
        "- pytorch의 `dataloader`를 이용하기 위해서는 `torch.utils.data.Dataset` 클래스를 상속한 클래스의 선언이 필요하다.\n",
        "- 클래스 내에 `__init__`, `__getitem__`, `__len__`의 3개의 메소드를 선언하여 오버라이드한다."
      ],
      "metadata": {
        "id": "i837jqmdjrGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class semiconductorDataset(Dataset): # inheritin from Dataset class\n",
        "\n",
        "    def __init__(self, csv_file, root_dir=\"\", transform=None):\n",
        "        self.annotation_df = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir # root directory of images, leave \"\" if using the image path column in the __getitem__ method\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.annotation_df) # return length (numer of rows) of the dataframe\n",
        "\n",
        "    ############ 실습 : annotation_df에 있는 이미지를 읽어 들어서, 변경한후\n",
        "    ############        읽어 들인 값을 return 하는 함수를 작성한다.\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        ##### Image 읽기\n",
        "        image_path = os.path.join(self.root_dir, self.annotation_df.iloc[idx, 1]) #use image path column (index = 1) in csv file\n",
        "        image = cv2.imread(image_path) # read image by cv2\n",
        "        #### 이미지를 Channel순서를 변경\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # convert from BGR to RGB for matplotlib\n",
        "        #### 이미지 Transform\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        #### 이미지에 대한 추가 정보 확인\n",
        "        class_name = self.annotation_df.iloc[idx, 2] # use class name column (index = 2) in csv file\n",
        "        class_index = self.annotation_df.iloc[idx, 3] # use class index column (index = 3) in csv file\n",
        "\n",
        "        return image, class_name, class_index"
      ],
      "metadata": {
        "id": "qOUmcMyjYn-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://pytorch.org/vision/stable/auto_examples/plot_transforms.html#sphx-glr-auto-examples-plot-transforms-py\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(), # PIL Image를 Tensor로 변경\n",
        "    transforms.Resize((100,100), antialias=True), # 크기 변경\n",
        "    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)), # Normalize\n",
        "    transforms.Grayscale(), # Gray Scale로 변경\n",
        "    transforms.RandomAdjustSharpness(sharpness_factor=2), # randomly adjusts the sharpness\n",
        "    transforms.RandomAutocontrast() # 임의로 Contrast변경\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(), # PIL Image를 Tensor로 변경\n",
        "    transforms.Resize((100,100), antialias=True), # 크기 변경\n",
        "    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)), # Normalize\n",
        "    transforms.Grayscale(), # Gray Scale로 변경\n",
        "])\n",
        "\n",
        "##### 실습 : train_dataset 선언\n",
        "##### 실습 : test_dataset 선언\n",
        "dataset = semiconductorDataset(csv_file='train.csv', root_dir=\"\", transform=transform)\n",
        "test_dataset = semiconductorDataset(csv_file='test.csv', root_dir=\"\", transform=transform_test)"
      ],
      "metadata": {
        "id": "aH1Zej7hLxxR"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset을 train 과 validation데이터로 나눈다.\n",
        "# Pytorch DataSet 을 나눌때에는 random_split을 수행한다.\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "train_len = int(len(dataset) * 0.8)\n",
        "val_len = len(dataset) - train_len\n",
        "\n",
        "train_dataset, val_dataset = random_split(dataset, [train_len, val_len])\n",
        "len(train_dataset), len(val_dataset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCKz1otVEKdh",
        "outputId": "277bd102-6039-4172-ef6e-0c0cd722e117"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(547, 137)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Batch 단위 학습을 위한 DataLoader 선언\n",
        " - Dataset내부의 샘플들을 batch 크기로 추출\n",
        " - Batch Size는 1step에 들어간 데이터의 개수\n",
        " - Epoch 마다 데이터를 섞어(Shuffle) Overfitting을 방지\n",
        " - 병렬처리를 지원하여 데이터 검색 속도를 향상\n"
      ],
      "metadata": {
        "id": "m5pV5UK4kBiR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VGG6를 이용하여 학습을 수행한다\n",
        "![](https://drive.google.com/uc?export=view&id=1vLrvhxczx1ZCOH05cxzzESylaOaF1Uj2)\n"
      ],
      "metadata": {
        "id": "WhDfo_bXniHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class VGG_BatchNormTorch(nn.Module):\n",
        "  def __init__(self, in_channels, out_features):\n",
        "    super(VGG_BatchNormTorch, self).__init__()\n",
        "\n",
        "    ###### 실습 : Gray이미지 이므로 in_channel =1 로 선언한다\n",
        "    self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=32, kernel_size=3, padding=1)\n",
        "    self.norm1 = torch.nn.BatchNorm2d(32)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1)\n",
        "    self.norm2 = torch.nn.BatchNorm2d(32)\n",
        "\n",
        "    self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "    self.norm3 = torch.nn.BatchNorm2d(64)\n",
        "\n",
        "    self.conv4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
        "    self.norm4 = torch.nn.BatchNorm2d(64)\n",
        "\n",
        "    self.conv5 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
        "    #### 실습 : Batch Norm 을 Pytorch의 값으로 변경한다\n",
        "    self.norm5 = torch.nn.BatchNorm2d(128)\n",
        "    self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "    #### 실습 : Batch Norm 을 Pytorch의 값으로 변경한다\n",
        "    self.norm6 = torch.nn.BatchNorm2d(128)\n",
        "\n",
        "    self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2) #Maxpooling layer to change feature size\n",
        "    self.avg_pool = nn.AdaptiveAvgPool2d(output_size = (1, 1)) #Note that average pooling layer is not adopted in original VGG architecture. We use average pooling layer to make the architecture for experiment simple.\n",
        "\n",
        "    ###### 실습 : 11개의 Label이 있으므로 out_features=11로 선언한다\n",
        "    self.fc = nn.Linear(in_features=128, out_features=out_features)\n",
        "\n",
        "  def forward(self, x):\n",
        "    #### 실습 : Batch Norm을 Convolution 이후에 선언\n",
        "    x = self.norm1(self.conv1(x))\n",
        "    x = F.relu(x)\n",
        "    x = self.norm2(self.conv2(x))\n",
        "    x = F.relu(x)\n",
        "    x = self.max_pool(x)\n",
        "\n",
        "    x = self.norm3(self.conv3(x))\n",
        "    x = F.relu(x)\n",
        "    x = self.norm4(self.conv4(x))\n",
        "    x = F.relu(x)\n",
        "    x = self.max_pool(x)\n",
        "\n",
        "    x = self.norm5(self.conv5(x))\n",
        "    x = F.relu(x)\n",
        "    x = self.norm6(self.conv6(x))\n",
        "    x = F.relu(x)\n",
        "\n",
        "    x = self.avg_pool(x)\n",
        "    x = x.view(-1, 128)\n",
        "    x = self.fc(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "QY8Iolz6gvHn"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "            path (str): Path for the checkpoint to be saved to.\n",
        "                            Default: 'checkpoint.pt'\n",
        "            trace_func (function): trace print function.\n",
        "                            Default: print\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.trace_func = trace_func\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss"
      ],
      "metadata": {
        "id": "s08D1R1KEnIe"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, data_loader, val_loader, early_stopping, criterion, optimizer, n_epoch):\n",
        "  ### 실습 : 학습 중임을 알림\n",
        "  model.train() ###\n",
        "  for epoch in range(n_epoch):\n",
        "    running_loss = 0\n",
        "    for i, (images, _, labels) in enumerate(data_loader):\n",
        "\n",
        "      images, labels = images.cuda(), labels.cuda()\n",
        "      outputs = model(images)\n",
        "      loss = criterion(outputs, labels)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      running_loss += loss.item()\n",
        "      if (i + 1) % 100 == 0:\n",
        "        print('iteration: [{}/{}]'.format(i + 1, len(data_loader)))\n",
        "\n",
        "    # 각 epoch 이후 validation 수행\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    for images, _, labels in val_loader:\n",
        "      images, labels = images.cuda(), labels.cuda()\n",
        "      outputs = model(images)\n",
        "      vloss = criterion(outputs, labels)\n",
        "\n",
        "      val_loss += vloss\n",
        "\n",
        "    # early stopping을 체크\n",
        "    early_stopping(val_loss, model)\n",
        "\n",
        "    # overfitting 발생 시 학습 종료\n",
        "    if early_stopping.early_stop:\n",
        "      break\n",
        "\n",
        "    # 원래 상태로 돌아옴\n",
        "    model.train()\n",
        "    running_loss = running_loss/len(data_loader)\n",
        "    val_loss = val_loss / len(val_loader)\n",
        "    print(f'Epoch {epoch + 1}, train_loss = {running_loss:.3f}, val_loss = {val_loss:.3f}')"
      ],
      "metadata": {
        "id": "FA4tQ_CXEsox"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval(model, data_loader):\n",
        "  #### 실습 : 평가를 위해서는 eval()을 선언\n",
        "  model.eval()\n",
        "  total = 0\n",
        "  correct = 0\n",
        "\n",
        "  preds = []\n",
        "  trues = []\n",
        "  #### 실습 : Gradient를 타지 않아야 한다\n",
        "  with torch.no_grad():\n",
        "    for images, _, labels in data_loader:\n",
        "      images, labels = images.cuda(), labels.cuda()\n",
        "      outputs = model(images)\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "      preds.append(predicted.detach().cpu().numpy())\n",
        "      trues.append(labels.detach().cpu().numpy())\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "\n",
        "  print('Test Accuracy: {}%'.format(accuracy))\n",
        "  return preds, trues\n"
      ],
      "metadata": {
        "id": "Reds16kIjVDW"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reset_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)"
      ],
      "metadata": {
        "id": "RLI00mauwDyZ"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### 실습 : torch.utils.DataLoader를 이용하여 데이터를 load. Batch 크기를 10으로 한다.\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset,batch_size=10, shuffle=True, num_workers=2)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=10, shuffle=False)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=10, shuffle=False)"
      ],
      "metadata": {
        "id": "-Ayz0YcTEYZ6"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reset_seed(2020)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "vgg_batchnorm_model = VGG_BatchNormTorch(in_channels=1, out_features=5).to(\"cuda\")\n",
        "optimizer = optim.Adam(params=vgg_batchnorm_model.parameters())\n",
        "\n",
        "earlystop = EarlyStopping(patience=7)\n",
        "train(vgg_batchnorm_model, train_dataloader, val_dataloader, earlystop,  criterion, optimizer, n_epoch=50)"
      ],
      "metadata": {
        "id": "t85o-4CZve4T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9eed29e8-d77c-4192-8064-53c230712325"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, train_loss = 1.338, val_loss = 1.331\n",
            "Epoch 2, train_loss = 1.255, val_loss = 1.271\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 3, train_loss = 1.211, val_loss = 1.305\n",
            "Epoch 4, train_loss = 1.196, val_loss = 1.190\n",
            "Epoch 5, train_loss = 1.130, val_loss = 1.140\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 6, train_loss = 1.051, val_loss = 1.154\n",
            "EarlyStopping counter: 2 out of 7\n",
            "Epoch 7, train_loss = 1.009, val_loss = 1.358\n",
            "Epoch 8, train_loss = 0.966, val_loss = 1.102\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 9, train_loss = 0.899, val_loss = 1.416\n",
            "Epoch 10, train_loss = 0.808, val_loss = 0.804\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 11, train_loss = 0.750, val_loss = 0.956\n",
            "EarlyStopping counter: 2 out of 7\n",
            "Epoch 12, train_loss = 0.700, val_loss = 0.993\n",
            "Epoch 13, train_loss = 0.640, val_loss = 0.706\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 14, train_loss = 0.640, val_loss = 2.789\n",
            "EarlyStopping counter: 2 out of 7\n",
            "Epoch 15, train_loss = 0.538, val_loss = 0.870\n",
            "EarlyStopping counter: 3 out of 7\n",
            "Epoch 16, train_loss = 0.518, val_loss = 1.436\n",
            "Epoch 17, train_loss = 0.457, val_loss = 0.569\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 18, train_loss = 0.468, val_loss = 2.426\n",
            "EarlyStopping counter: 2 out of 7\n",
            "Epoch 19, train_loss = 0.464, val_loss = 0.618\n",
            "Epoch 20, train_loss = 0.385, val_loss = 0.502\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 21, train_loss = 0.378, val_loss = 0.737\n",
            "EarlyStopping counter: 2 out of 7\n",
            "Epoch 22, train_loss = 0.389, val_loss = 0.912\n",
            "EarlyStopping counter: 3 out of 7\n",
            "Epoch 23, train_loss = 0.371, val_loss = 0.680\n",
            "EarlyStopping counter: 4 out of 7\n",
            "Epoch 24, train_loss = 0.352, val_loss = 0.856\n",
            "EarlyStopping counter: 5 out of 7\n",
            "Epoch 25, train_loss = 0.335, val_loss = 1.862\n",
            "EarlyStopping counter: 6 out of 7\n",
            "Epoch 26, train_loss = 0.341, val_loss = 1.071\n",
            "EarlyStopping counter: 7 out of 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 정확도를 평가해 봅시다\n",
        "* 데이터가 너무 적어서 평가 데이터에 대한 정확도를 봅니다"
      ],
      "metadata": {
        "id": "8d4AUYGHJzQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# early stop 된 객체를 load 한다.\n",
        "state_dict = torch.load('checkpoint.pt')\n",
        "vgg_batchnorm_model = VGG_BatchNormTorch(in_channels=1, out_features=5).to(\"cuda\")\n",
        "vgg_batchnorm_model.load_state_dict(state_dict)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Kk-vnWbpwNz",
        "outputId": "ca254bc4-2d22-4fdb-c65e-a9ff5dc84819"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_r, trues_r = eval(vgg_batchnorm_model, train_dataloader)"
      ],
      "metadata": {
        "id": "sOZgeQXPi49W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7703b730-9974-47d2-e3d4-d09d4639da7e"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 89.03107861060329%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds, trues = eval(vgg_batchnorm_model, test_dataloader)"
      ],
      "metadata": {
        "id": "cdj0G1XrrBkv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbd3c700-fad9-45c8-dcc6-1adc76f7dc5f"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 87.71929824561404%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_label = np.stack(preds[:-1]).flatten()\n",
        "test_labels = np.stack(trues[:-1]).flatten()\n",
        "prediction_label, test_labels"
      ],
      "metadata": {
        "id": "xQVX4HIMjyZa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb928dea-3be3-418f-e5aa-4032e75dda6c"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 0, 0, 1, 0, 0, 1, 3, 0, 1, 0, 0, 1, 0, 0, 2, 0, 2, 0, 2, 2, 3,\n",
              "        2, 4, 0, 0, 0, 3, 0, 0, 1, 4, 1, 0, 0, 2, 3, 4, 1, 1, 0, 0, 0, 0,\n",
              "        3, 0, 3, 0, 1, 0, 3, 3, 4, 2, 0, 0, 3, 0, 0, 4, 0, 0, 0, 3, 3, 4,\n",
              "        2, 4, 0, 0, 3, 0, 2, 0, 1, 0, 1, 0, 0, 0, 2, 0, 0, 4, 2, 0, 0, 1,\n",
              "        0, 0, 3, 0, 0, 0, 1, 4, 3, 3, 0, 0, 0, 2, 0, 0, 4, 2, 4, 0, 0, 1,\n",
              "        0, 3, 0, 4, 0, 0, 0, 0, 1, 1, 0, 1, 4, 4, 3, 0, 4, 3, 1, 1, 4, 3,\n",
              "        3, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 3, 0, 0, 0, 0, 0, 3, 0, 4, 0, 1,\n",
              "        0, 1, 0, 3, 3, 0, 3, 2, 2, 0, 4, 0, 3, 0, 0, 4]),\n",
              " array([0, 0, 0, 1, 0, 0, 1, 3, 0, 1, 0, 0, 1, 0, 0, 2, 0, 2, 0, 2, 2, 3,\n",
              "        2, 4, 0, 0, 0, 3, 0, 0, 1, 4, 1, 0, 0, 2, 2, 4, 1, 1, 0, 0, 1, 0,\n",
              "        3, 0, 0, 0, 1, 0, 3, 0, 4, 2, 0, 0, 2, 0, 0, 4, 0, 0, 0, 3, 3, 4,\n",
              "        2, 4, 0, 0, 0, 0, 3, 0, 1, 0, 1, 0, 0, 0, 2, 0, 0, 4, 2, 0, 0, 1,\n",
              "        0, 0, 1, 0, 0, 2, 1, 4, 0, 3, 4, 0, 0, 1, 0, 0, 4, 2, 4, 0, 0, 1,\n",
              "        0, 1, 0, 4, 0, 0, 0, 0, 0, 1, 0, 0, 4, 4, 3, 0, 4, 0, 1, 1, 4, 0,\n",
              "        3, 1, 0, 0, 0, 0, 0, 2, 0, 0, 2, 3, 0, 0, 0, 0, 0, 3, 0, 4, 0, 1,\n",
              "        0, 1, 1, 3, 0, 0, 0, 2, 2, 0, 4, 0, 3, 0, 0, 4]))"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(test_labels, prediction_label))"
      ],
      "metadata": {
        "id": "ZWlrVMQQkICA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "758bf020-861f-4882-8228-165be8655836"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.88      0.87        92\n",
            "           1       0.79      0.76      0.78        25\n",
            "           2       0.84      0.89      0.86        18\n",
            "           3       0.67      0.67      0.67        15\n",
            "           4       1.00      0.90      0.95        20\n",
            "\n",
            "    accuracy                           0.85       170\n",
            "   macro avg       0.83      0.82      0.83       170\n",
            "weighted avg       0.85      0.85      0.85       170\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RGB로 학습 후 평가해 본다"
      ],
      "metadata": {
        "id": "qJ-2OryDzP4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://pytorch.org/vision/stable/auto_examples/plot_transforms.html#sphx-glr-auto-examples-plot-transforms-py\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(), # PIL Image를 Tensor로 변경\n",
        "    transforms.Resize((100,100), antialias=True), # 크기 변경\n",
        "    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)), # Normalize\n",
        "    transforms.RandomAdjustSharpness(sharpness_factor=2), # randomly adjusts the sharpness\n",
        "    transforms.RandomAutocontrast() # 임의로 Contrast변경\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(), # PIL Image를 Tensor로 변경\n",
        "    transforms.Resize((100,100), antialias=True), # 크기 변경\n",
        "    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)), # Normalize\n",
        "])\n",
        "\n",
        "##### 실습 : train_dataset 선언\n",
        "##### 실습 : test_dataset 선언\n",
        "dataset = semiconductorDataset(csv_file='train.csv', root_dir=\"\", transform=transform)\n",
        "test_dataset = semiconductorDataset(csv_file='test.csv', root_dir=\"\", transform=transform_test)"
      ],
      "metadata": {
        "id": "k-skeZ8GzPQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset을 train 과 validation데이터로 나눈다.\n",
        "# Pytorch DataSet 을 나눌때에는 random_split을 수행한다.\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "train_len = int(len(dataset) * 0.8)\n",
        "val_len = len(dataset) - train_len\n",
        "\n",
        "train_dataset, val_dataset = random_split(dataset, [train_len, val_len])\n",
        "len(train_dataset), len(val_dataset)"
      ],
      "metadata": {
        "id": "tD8prkyfiplA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab7badcf-9fb5-4bf8-a872-fc84f0b9ebe5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(547, 137)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### 실습 : torch.utils.DataLoader를 이용하여 데이터를 load. Batch 크기를 10으로 한다.\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset,batch_size=10, shuffle=True, num_workers=2)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=10, shuffle=False)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=10, shuffle=False)"
      ],
      "metadata": {
        "id": "OExBBQdIiyp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reset_seed(2020)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "############### 실습 : 입력 Channel의 개수는 3\n",
        "vgg_batchnorm_model = VGG_BatchNormTorch(in_channels=3, out_features=5).to(\"cuda\")\n",
        "optimizer = optim.Adam(params=vgg_batchnorm_model.parameters(), lr=0.00005)\n",
        "earlystop = EarlyStopping(patience=7)\n",
        "\n",
        "train(vgg_batchnorm_model, train_dataloader, val_dataloader, earlystop,  criterion, optimizer, n_epoch=50)"
      ],
      "metadata": {
        "id": "E4PSMYpRzQ0B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f1aad3a-6385-4cd4-db69-b80858bed295"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, train_loss = 1.371, val_loss = 1.292\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 2, train_loss = 1.252, val_loss = 1.424\n",
            "EarlyStopping counter: 2 out of 7\n",
            "Epoch 3, train_loss = 1.232, val_loss = 1.322\n",
            "Epoch 4, train_loss = 1.154, val_loss = 1.167\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 5, train_loss = 1.090, val_loss = 1.365\n",
            "Epoch 6, train_loss = 1.009, val_loss = 1.013\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 7, train_loss = 0.907, val_loss = 1.418\n",
            "Epoch 8, train_loss = 0.901, val_loss = 0.998\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 9, train_loss = 0.718, val_loss = 1.011\n",
            "Epoch 10, train_loss = 0.671, val_loss = 0.798\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 11, train_loss = 0.633, val_loss = 1.396\n",
            "Epoch 12, train_loss = 0.563, val_loss = 0.718\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 13, train_loss = 0.547, val_loss = 1.562\n",
            "Epoch 14, train_loss = 0.476, val_loss = 0.634\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 15, train_loss = 0.474, val_loss = 0.762\n",
            "EarlyStopping counter: 2 out of 7\n",
            "Epoch 16, train_loss = 0.412, val_loss = 0.987\n",
            "EarlyStopping counter: 3 out of 7\n",
            "Epoch 17, train_loss = 0.397, val_loss = 0.961\n",
            "EarlyStopping counter: 4 out of 7\n",
            "Epoch 18, train_loss = 0.354, val_loss = 0.698\n",
            "EarlyStopping counter: 5 out of 7\n",
            "Epoch 19, train_loss = 0.373, val_loss = 1.149\n",
            "Epoch 20, train_loss = 0.366, val_loss = 0.585\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 21, train_loss = 0.385, val_loss = 1.323\n",
            "EarlyStopping counter: 2 out of 7\n",
            "Epoch 22, train_loss = 0.369, val_loss = 1.263\n",
            "EarlyStopping counter: 3 out of 7\n",
            "Epoch 23, train_loss = 0.304, val_loss = 1.106\n",
            "EarlyStopping counter: 4 out of 7\n",
            "Epoch 24, train_loss = 0.279, val_loss = 1.250\n",
            "EarlyStopping counter: 5 out of 7\n",
            "Epoch 25, train_loss = 0.284, val_loss = 0.775\n",
            "Epoch 26, train_loss = 0.284, val_loss = 0.479\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 27, train_loss = 0.287, val_loss = 0.631\n",
            "EarlyStopping counter: 2 out of 7\n",
            "Epoch 28, train_loss = 0.288, val_loss = 2.092\n",
            "EarlyStopping counter: 3 out of 7\n",
            "Epoch 29, train_loss = 0.240, val_loss = 0.614\n",
            "EarlyStopping counter: 4 out of 7\n",
            "Epoch 30, train_loss = 0.272, val_loss = 1.276\n",
            "EarlyStopping counter: 5 out of 7\n",
            "Epoch 31, train_loss = 0.263, val_loss = 0.867\n",
            "EarlyStopping counter: 6 out of 7\n",
            "Epoch 32, train_loss = 0.255, val_loss = 1.540\n",
            "EarlyStopping counter: 7 out of 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_r, trues_r = eval(vgg_batchnorm_model, train_dataloader)"
      ],
      "metadata": {
        "id": "5HtIt4Va0KmL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54bab4f0-c7cd-4b99-a06f-91f79c55f595"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 87.56855575868373%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds, trues = eval(vgg_batchnorm_model, test_dataloader)"
      ],
      "metadata": {
        "id": "TjaBZO4SksMT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac49e319-5d62-4fc2-c1a2-7225b9405a8f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 84.7953216374269%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_label = np.stack(preds[:-1]).flatten()\n",
        "test_labels = np.stack(trues[:-1]).flatten()\n",
        "prediction_label, test_labels"
      ],
      "metadata": {
        "id": "Jbd_F7ozkyJ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fd55ec0-c9ca-4503-c60e-15eb318737ab"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 2, 0, 2, 0, 2, 2, 3,\n",
              "        2, 4, 0, 0, 0, 3, 0, 0, 1, 0, 1, 0, 0, 2, 0, 4, 0, 1, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 1, 0, 0, 0, 4, 0, 3, 0, 3, 0, 0, 4, 0, 0, 0, 0, 0, 4,\n",
              "        2, 4, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 2, 0, 0, 4, 2, 0, 0, 1,\n",
              "        0, 0, 0, 0, 0, 0, 1, 4, 0, 3, 0, 0, 0, 0, 0, 0, 4, 2, 4, 0, 0, 1,\n",
              "        0, 0, 0, 4, 0, 0, 0, 0, 0, 1, 0, 0, 4, 4, 0, 0, 4, 0, 1, 1, 4, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 3, 0, 0, 0, 0, 0, 0, 0, 4, 0, 1,\n",
              "        0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 4, 0, 0, 0, 0, 4]),\n",
              " array([0, 0, 0, 1, 0, 0, 1, 3, 0, 1, 0, 0, 1, 0, 0, 2, 0, 2, 0, 2, 2, 3,\n",
              "        2, 4, 0, 0, 0, 3, 0, 0, 1, 4, 1, 0, 0, 2, 2, 4, 1, 1, 0, 0, 1, 0,\n",
              "        3, 0, 0, 0, 1, 0, 3, 0, 4, 2, 0, 0, 2, 0, 0, 4, 0, 0, 0, 3, 3, 4,\n",
              "        2, 4, 0, 0, 0, 0, 3, 0, 1, 0, 1, 0, 0, 0, 2, 0, 0, 4, 2, 0, 0, 1,\n",
              "        0, 0, 1, 0, 0, 2, 1, 4, 0, 3, 4, 0, 0, 1, 0, 0, 4, 2, 4, 0, 0, 1,\n",
              "        0, 1, 0, 4, 0, 0, 0, 0, 0, 1, 0, 0, 4, 4, 3, 0, 4, 0, 1, 1, 4, 0,\n",
              "        3, 1, 0, 0, 0, 0, 0, 2, 0, 0, 2, 3, 0, 0, 0, 0, 0, 3, 0, 4, 0, 1,\n",
              "        0, 1, 1, 3, 0, 0, 0, 2, 2, 0, 4, 0, 3, 0, 0, 4]))"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "########### 실습 : 분류 성능을 평가해 봅니다.\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(test_labels, prediction_label))"
      ],
      "metadata": {
        "id": "QvVspfx1f9tk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ensemble 수행 - 흑백"
      ],
      "metadata": {
        "id": "A9_Vp65BqTTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset 및 dataloader생성\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(), # PIL Image를 Tensor로 변경\n",
        "    transforms.Resize((100,100), antialias=True), # 크기 변경\n",
        "    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)), # Normalize\n",
        "    transforms.Grayscale(), # Gray Scale로 변경\n",
        "    transforms.RandomAdjustSharpness(sharpness_factor=2), # randomly adjusts the sharpness\n",
        "    transforms.RandomAutocontrast() # 임의로 Contrast변경\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(), # PIL Image를 Tensor로 변경\n",
        "    transforms.Resize((100,100), antialias=True), # 크기 변경\n",
        "    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)), # Normalize\n",
        "    transforms.Grayscale(), # Gray Scale로 변경\n",
        "])\n",
        "\n",
        "dataset = semiconductorDataset(csv_file='train.csv', root_dir=\"\", transform=transform)\n",
        "test_dataset = semiconductorDataset(csv_file='test.csv', root_dir=\"\", transform=transform_test)\n",
        "\n",
        "# dataset을 train 과 validation데이터로 나눈다.\n",
        "from torch.utils.data import random_split\n",
        "train_len = int(len(dataset) * 0.8)\n",
        "val_len = len(dataset) - train_len\n",
        "train_dataset, val_dataset = random_split(dataset, [train_len, val_len])\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset,batch_size=10, shuffle=True, num_workers=2)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=10, shuffle=False)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=10, shuffle=False)"
      ],
      "metadata": {
        "id": "Ef4HKNVIqqlw"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습을 반복적으로 수행\n",
        "for itr in range(5):\n",
        "  reset_seed(105 + itr)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  vgg_batchnorm_model = VGG_BatchNormTorch(in_channels=1, out_features=5).to(\"cuda\")\n",
        "  optimizer = optim.Adam(params=vgg_batchnorm_model.parameters(), lr=0.00005)\n",
        "  earlystop = EarlyStopping(patience=7)\n",
        "\n",
        "  train_dataloader = torch.utils.data.DataLoader(train_dataset,batch_size=10, shuffle=True, num_workers=2)\n",
        "  val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=10, shuffle=False)\n",
        "\n",
        "  train(vgg_batchnorm_model, train_dataloader, val_dataloader, earlystop,  criterion, optimizer, n_epoch=50)\n",
        "\n",
        "  # 저장된 checkpoint를 다른이름으로 저장\n",
        "  state_dict = torch.load('checkpoint.pt')\n",
        "  vgg_batchnorm_model = VGG_BatchNormTorch(in_channels=1, out_features=5).to(\"cuda\")\n",
        "  vgg_batchnorm_model.load_state_dict(state_dict)\n",
        "  torch.save(vgg_batchnorm_model.state_dict(), f\"ckpt_{itr}.pt\")\n",
        "  print(f\"Save ckpt_{itr}.pt\")\n"
      ],
      "metadata": {
        "id": "gSJlCPDXmUoD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bb4a53d-fa46-49f7-99cf-40051ed7c6be"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, train_loss = 1.448, val_loss = 1.416\n",
            "Epoch 2, train_loss = 1.336, val_loss = 1.379\n",
            "Epoch 3, train_loss = 1.274, val_loss = 1.364\n",
            "Epoch 4, train_loss = 1.240, val_loss = 1.343\n",
            "Epoch 5, train_loss = 1.220, val_loss = 1.291\n",
            "Epoch 6, train_loss = 1.206, val_loss = 1.287\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 7, train_loss = 1.174, val_loss = 1.294\n",
            "Epoch 8, train_loss = 1.187, val_loss = 1.263\n",
            "Epoch 9, train_loss = 1.162, val_loss = 1.242\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 10, train_loss = 1.136, val_loss = 1.262\n",
            "Epoch 11, train_loss = 1.127, val_loss = 1.185\n",
            "Epoch 12, train_loss = 1.105, val_loss = 1.173\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 13, train_loss = 1.093, val_loss = 1.176\n",
            "Epoch 14, train_loss = 1.093, val_loss = 1.169\n",
            "Epoch 15, train_loss = 1.052, val_loss = 1.115\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 16, train_loss = 1.035, val_loss = 1.146\n",
            "Epoch 17, train_loss = 1.005, val_loss = 1.078\n",
            "Epoch 18, train_loss = 1.013, val_loss = 1.026\n",
            "Epoch 19, train_loss = 0.950, val_loss = 1.020\n",
            "Epoch 20, train_loss = 0.942, val_loss = 0.985\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 21, train_loss = 0.913, val_loss = 1.011\n",
            "Epoch 22, train_loss = 0.896, val_loss = 0.910\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 23, train_loss = 0.869, val_loss = 0.996\n",
            "Epoch 24, train_loss = 0.863, val_loss = 0.874\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 25, train_loss = 0.838, val_loss = 0.880\n",
            "EarlyStopping counter: 2 out of 7\n",
            "Epoch 26, train_loss = 0.812, val_loss = 0.896\n",
            "Epoch 27, train_loss = 0.814, val_loss = 0.841\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 28, train_loss = 0.788, val_loss = 1.488\n",
            "EarlyStopping counter: 2 out of 7\n",
            "Epoch 29, train_loss = 0.774, val_loss = 0.906\n",
            "EarlyStopping counter: 3 out of 7\n",
            "Epoch 30, train_loss = 0.755, val_loss = 0.884\n",
            "Epoch 31, train_loss = 0.745, val_loss = 0.810\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 32, train_loss = 0.724, val_loss = 0.955\n",
            "Epoch 33, train_loss = 0.711, val_loss = 0.756\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 34, train_loss = 0.691, val_loss = 0.805\n",
            "EarlyStopping counter: 2 out of 7\n",
            "Epoch 35, train_loss = 0.682, val_loss = 0.822\n",
            "EarlyStopping counter: 3 out of 7\n",
            "Epoch 36, train_loss = 0.679, val_loss = 0.776\n",
            "EarlyStopping counter: 4 out of 7\n",
            "Epoch 37, train_loss = 0.639, val_loss = 0.914\n",
            "Epoch 38, train_loss = 0.656, val_loss = 0.734\n",
            "Epoch 39, train_loss = 0.630, val_loss = 0.705\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 40, train_loss = 0.609, val_loss = 0.723\n",
            "Epoch 41, train_loss = 0.610, val_loss = 0.690\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 42, train_loss = 0.602, val_loss = 0.760\n",
            "Epoch 43, train_loss = 0.582, val_loss = 0.657\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 44, train_loss = 0.582, val_loss = 0.701\n",
            "EarlyStopping counter: 2 out of 7\n",
            "Epoch 45, train_loss = 0.573, val_loss = 0.668\n",
            "Epoch 46, train_loss = 0.562, val_loss = 0.605\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 47, train_loss = 0.565, val_loss = 0.629\n",
            "EarlyStopping counter: 2 out of 7\n",
            "Epoch 48, train_loss = 0.554, val_loss = 0.629\n",
            "Epoch 49, train_loss = 0.547, val_loss = 0.583\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 50, train_loss = 0.561, val_loss = 0.604\n",
            "Save ckpt_0.pt\n",
            "Epoch 1, train_loss = 1.663, val_loss = 1.581\n",
            "Epoch 2, train_loss = 1.550, val_loss = 1.548\n",
            "Epoch 3, train_loss = 1.426, val_loss = 1.543\n",
            "Epoch 4, train_loss = 1.372, val_loss = 1.423\n",
            "Epoch 5, train_loss = 1.321, val_loss = 1.343\n",
            "Epoch 6, train_loss = 1.271, val_loss = 1.314\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 7, train_loss = 1.251, val_loss = 1.315\n",
            "EarlyStopping counter: 2 out of 7\n",
            "Epoch 8, train_loss = 1.239, val_loss = 1.320\n",
            "Epoch 9, train_loss = 1.222, val_loss = 1.288\n",
            "Epoch 10, train_loss = 1.196, val_loss = 1.252\n",
            "Epoch 11, train_loss = 1.175, val_loss = 1.236\n",
            "Epoch 12, train_loss = 1.176, val_loss = 1.224\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 13, train_loss = 1.157, val_loss = 1.257\n",
            "Epoch 14, train_loss = 1.161, val_loss = 1.222\n",
            "Epoch 15, train_loss = 1.108, val_loss = 1.194\n",
            "Epoch 16, train_loss = 1.079, val_loss = 1.161\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 17, train_loss = 1.080, val_loss = 1.172\n",
            "Epoch 18, train_loss = 1.049, val_loss = 1.154\n",
            "Epoch 19, train_loss = 1.020, val_loss = 1.063\n",
            "Epoch 20, train_loss = 0.998, val_loss = 1.030\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 21, train_loss = 0.970, val_loss = 1.046\n",
            "Epoch 22, train_loss = 0.982, val_loss = 1.002\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 23, train_loss = 0.933, val_loss = 1.129\n",
            "EarlyStopping counter: 2 out of 7\n",
            "Epoch 24, train_loss = 0.901, val_loss = 1.008\n",
            "Epoch 25, train_loss = 0.900, val_loss = 0.990\n",
            "Epoch 26, train_loss = 0.880, val_loss = 0.923\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 27, train_loss = 0.847, val_loss = 1.010\n",
            "Epoch 28, train_loss = 0.866, val_loss = 0.899\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 29, train_loss = 0.833, val_loss = 0.937\n",
            "Epoch 30, train_loss = 0.799, val_loss = 0.887\n",
            "Epoch 31, train_loss = 0.785, val_loss = 0.803\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 32, train_loss = 0.778, val_loss = 0.832\n",
            "Epoch 33, train_loss = 0.761, val_loss = 0.783\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 34, train_loss = 0.753, val_loss = 0.789\n",
            "EarlyStopping counter: 2 out of 7\n",
            "Epoch 35, train_loss = 0.734, val_loss = 0.810\n",
            "EarlyStopping counter: 3 out of 7\n",
            "Epoch 36, train_loss = 0.727, val_loss = 0.937\n",
            "EarlyStopping counter: 4 out of 7\n",
            "Epoch 37, train_loss = 0.709, val_loss = 0.823\n",
            "EarlyStopping counter: 5 out of 7\n",
            "Epoch 38, train_loss = 0.698, val_loss = 0.858\n",
            "EarlyStopping counter: 6 out of 7\n",
            "Epoch 39, train_loss = 0.680, val_loss = 0.828\n",
            "EarlyStopping counter: 7 out of 7\n",
            "Save ckpt_1.pt\n",
            "Epoch 1, train_loss = 1.674, val_loss = 1.498\n",
            "Epoch 2, train_loss = 1.512, val_loss = 1.498\n",
            "Epoch 3, train_loss = 1.433, val_loss = 1.465\n",
            "Epoch 4, train_loss = 1.369, val_loss = 1.419\n",
            "Epoch 5, train_loss = 1.318, val_loss = 1.361\n",
            "Epoch 6, train_loss = 1.288, val_loss = 1.331\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 7, train_loss = 1.250, val_loss = 1.333\n",
            "Epoch 8, train_loss = 1.231, val_loss = 1.295\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 9, train_loss = 1.219, val_loss = 1.296\n",
            "EarlyStopping counter: 2 out of 7\n",
            "Epoch 10, train_loss = 1.193, val_loss = 1.310\n",
            "Epoch 11, train_loss = 1.178, val_loss = 1.276\n",
            "Epoch 12, train_loss = 1.173, val_loss = 1.251\n",
            "Epoch 13, train_loss = 1.145, val_loss = 1.233\n",
            "Epoch 14, train_loss = 1.129, val_loss = 1.217\n",
            "Epoch 15, train_loss = 1.130, val_loss = 1.201\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 16, train_loss = 1.107, val_loss = 1.221\n",
            "Epoch 17, train_loss = 1.072, val_loss = 1.145\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 18, train_loss = 1.051, val_loss = 1.155\n",
            "Epoch 19, train_loss = 1.038, val_loss = 1.083\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 20, train_loss = 1.027, val_loss = 1.194\n",
            "Epoch 21, train_loss = 1.002, val_loss = 1.028\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 22, train_loss = 0.964, val_loss = 1.107\n",
            "Epoch 23, train_loss = 0.938, val_loss = 0.943\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 24, train_loss = 0.915, val_loss = 1.062\n",
            "EarlyStopping counter: 2 out of 7\n",
            "Epoch 25, train_loss = 0.897, val_loss = 0.945\n",
            "EarlyStopping counter: 3 out of 7\n",
            "Epoch 26, train_loss = 0.868, val_loss = 1.006\n",
            "Epoch 27, train_loss = 0.827, val_loss = 0.876\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 28, train_loss = 0.800, val_loss = 0.885\n",
            "EarlyStopping counter: 2 out of 7\n",
            "Epoch 29, train_loss = 0.780, val_loss = 0.909\n",
            "Epoch 30, train_loss = 0.799, val_loss = 0.838\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 31, train_loss = 0.741, val_loss = 0.854\n",
            "EarlyStopping counter: 2 out of 7\n",
            "Epoch 32, train_loss = 0.768, val_loss = 0.864\n",
            "EarlyStopping counter: 3 out of 7\n",
            "Epoch 33, train_loss = 0.733, val_loss = 0.845\n",
            "Epoch 34, train_loss = 0.723, val_loss = 0.740\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 35, train_loss = 0.702, val_loss = 0.803\n",
            "Epoch 36, train_loss = 0.684, val_loss = 0.739\n",
            "Epoch 37, train_loss = 0.652, val_loss = 0.659\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 38, train_loss = 0.660, val_loss = 0.780\n",
            "EarlyStopping counter: 2 out of 7\n",
            "Epoch 39, train_loss = 0.636, val_loss = 0.767\n",
            "EarlyStopping counter: 3 out of 7\n",
            "Epoch 40, train_loss = 0.612, val_loss = 0.702\n",
            "Epoch 41, train_loss = 0.619, val_loss = 0.637\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 42, train_loss = 0.596, val_loss = 0.693\n",
            "EarlyStopping counter: 2 out of 7\n",
            "Epoch 43, train_loss = 0.581, val_loss = 0.660\n",
            "EarlyStopping counter: 3 out of 7\n",
            "Epoch 44, train_loss = 0.574, val_loss = 0.826\n",
            "EarlyStopping counter: 4 out of 7\n",
            "Epoch 45, train_loss = 0.560, val_loss = 0.742\n",
            "Epoch 46, train_loss = 0.555, val_loss = 0.623\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 47, train_loss = 0.531, val_loss = 0.745\n",
            "Epoch 48, train_loss = 0.530, val_loss = 0.606\n",
            "Epoch 49, train_loss = 0.514, val_loss = 0.596\n",
            "Epoch 50, train_loss = 0.516, val_loss = 0.558\n",
            "Save ckpt_2.pt\n",
            "Epoch 1, train_loss = 1.533, val_loss = 1.460\n",
            "Epoch 2, train_loss = 1.426, val_loss = 1.378\n",
            "Epoch 3, train_loss = 1.353, val_loss = 1.317\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 4, train_loss = 1.307, val_loss = 1.391\n",
            "EarlyStopping counter: 2 out of 7\n",
            "Epoch 5, train_loss = 1.261, val_loss = 1.324\n",
            "Epoch 6, train_loss = 1.247, val_loss = 1.287\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 7, train_loss = 1.229, val_loss = 1.298\n",
            "EarlyStopping counter: 2 out of 7\n",
            "Epoch 8, train_loss = 1.222, val_loss = 1.303\n",
            "EarlyStopping counter: 3 out of 7\n",
            "Epoch 9, train_loss = 1.202, val_loss = 1.289\n",
            "Epoch 10, train_loss = 1.182, val_loss = 1.270\n",
            "Epoch 11, train_loss = 1.167, val_loss = 1.261\n",
            "Epoch 12, train_loss = 1.145, val_loss = 1.239\n",
            "Epoch 13, train_loss = 1.134, val_loss = 1.199\n",
            "Epoch 14, train_loss = 1.113, val_loss = 1.197\n",
            "Epoch 15, train_loss = 1.103, val_loss = 1.165\n",
            "Epoch 16, train_loss = 1.071, val_loss = 1.119\n",
            "Epoch 17, train_loss = 1.078, val_loss = 1.105\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 18, train_loss = 1.056, val_loss = 1.162\n",
            "EarlyStopping counter: 2 out of 7\n",
            "Epoch 19, train_loss = 1.019, val_loss = 1.107\n",
            "Epoch 20, train_loss = 0.993, val_loss = 1.054\n",
            "Epoch 21, train_loss = 0.974, val_loss = 1.008\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 22, train_loss = 0.953, val_loss = 1.103\n",
            "EarlyStopping counter: 2 out of 7\n",
            "Epoch 23, train_loss = 0.909, val_loss = 1.069\n",
            "EarlyStopping counter: 3 out of 7\n",
            "Epoch 24, train_loss = 0.888, val_loss = 1.094\n",
            "Epoch 25, train_loss = 0.877, val_loss = 0.946\n",
            "Epoch 26, train_loss = 0.853, val_loss = 0.945\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 27, train_loss = 0.839, val_loss = 1.145\n",
            "EarlyStopping counter: 2 out of 7\n",
            "Epoch 28, train_loss = 0.837, val_loss = 1.089\n",
            "EarlyStopping counter: 3 out of 7\n",
            "Epoch 29, train_loss = 0.816, val_loss = 0.987\n",
            "EarlyStopping counter: 4 out of 7\n",
            "Epoch 30, train_loss = 0.766, val_loss = 1.180\n",
            "Epoch 31, train_loss = 0.774, val_loss = 0.750\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 32, train_loss = 0.752, val_loss = 0.796\n",
            "EarlyStopping counter: 2 out of 7\n",
            "Epoch 33, train_loss = 0.728, val_loss = 0.848\n",
            "EarlyStopping counter: 3 out of 7\n",
            "Epoch 34, train_loss = 0.713, val_loss = 0.884\n",
            "EarlyStopping counter: 4 out of 7\n",
            "Epoch 35, train_loss = 0.704, val_loss = 0.768\n",
            "Epoch 36, train_loss = 0.682, val_loss = 0.741\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 37, train_loss = 0.668, val_loss = 0.827\n",
            "Epoch 38, train_loss = 0.666, val_loss = 0.728\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 39, train_loss = 0.660, val_loss = 0.729\n",
            "EarlyStopping counter: 2 out of 7\n",
            "Epoch 40, train_loss = 0.612, val_loss = 1.080\n",
            "EarlyStopping counter: 3 out of 7\n",
            "Epoch 41, train_loss = 0.637, val_loss = 0.848\n",
            "Epoch 42, train_loss = 0.594, val_loss = 0.648\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 43, train_loss = 0.574, val_loss = 1.007\n",
            "Epoch 44, train_loss = 0.587, val_loss = 0.597\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 45, train_loss = 0.600, val_loss = 0.680\n",
            "EarlyStopping counter: 2 out of 7\n",
            "Epoch 46, train_loss = 0.580, val_loss = 0.678\n",
            "EarlyStopping counter: 3 out of 7\n",
            "Epoch 47, train_loss = 0.550, val_loss = 0.732\n",
            "EarlyStopping counter: 4 out of 7\n",
            "Epoch 48, train_loss = 0.554, val_loss = 0.636\n",
            "Epoch 49, train_loss = 0.549, val_loss = 0.568\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 50, train_loss = 0.540, val_loss = 0.680\n",
            "Save ckpt_3.pt\n",
            "Epoch 1, train_loss = 1.470, val_loss = 1.414\n",
            "Epoch 2, train_loss = 1.364, val_loss = 1.373\n",
            "Epoch 3, train_loss = 1.296, val_loss = 1.339\n",
            "Epoch 4, train_loss = 1.251, val_loss = 1.286\n",
            "Epoch 5, train_loss = 1.211, val_loss = 1.267\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 6, train_loss = 1.186, val_loss = 1.297\n",
            "Epoch 7, train_loss = 1.181, val_loss = 1.240\n",
            "Epoch 8, train_loss = 1.183, val_loss = 1.210\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 9, train_loss = 1.137, val_loss = 1.221\n",
            "Epoch 10, train_loss = 1.118, val_loss = 1.178\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 11, train_loss = 1.089, val_loss = 1.310\n",
            "Epoch 12, train_loss = 1.074, val_loss = 1.143\n",
            "Epoch 13, train_loss = 1.043, val_loss = 1.099\n",
            "Epoch 14, train_loss = 1.020, val_loss = 1.060\n",
            "Epoch 15, train_loss = 0.999, val_loss = 1.054\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 16, train_loss = 0.972, val_loss = 1.082\n",
            "EarlyStopping counter: 2 out of 7\n",
            "Epoch 17, train_loss = 0.966, val_loss = 1.127\n",
            "EarlyStopping counter: 3 out of 7\n",
            "Epoch 18, train_loss = 0.940, val_loss = 1.237\n",
            "Epoch 19, train_loss = 0.905, val_loss = 0.878\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 20, train_loss = 0.879, val_loss = 1.003\n",
            "Epoch 21, train_loss = 0.846, val_loss = 0.877\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 22, train_loss = 0.825, val_loss = 1.005\n",
            "EarlyStopping counter: 2 out of 7\n",
            "Epoch 23, train_loss = 0.806, val_loss = 1.022\n",
            "Epoch 24, train_loss = 0.816, val_loss = 0.856\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 25, train_loss = 0.741, val_loss = 0.942\n",
            "Epoch 26, train_loss = 0.756, val_loss = 0.790\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 27, train_loss = 0.733, val_loss = 1.049\n",
            "Epoch 28, train_loss = 0.719, val_loss = 0.779\n",
            "Epoch 29, train_loss = 0.705, val_loss = 0.720\n",
            "Epoch 30, train_loss = 0.668, val_loss = 0.695\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 31, train_loss = 0.678, val_loss = 0.832\n",
            "EarlyStopping counter: 2 out of 7\n",
            "Epoch 32, train_loss = 0.666, val_loss = 0.735\n",
            "EarlyStopping counter: 3 out of 7\n",
            "Epoch 33, train_loss = 0.631, val_loss = 0.741\n",
            "EarlyStopping counter: 4 out of 7\n",
            "Epoch 34, train_loss = 0.621, val_loss = 0.821\n",
            "Epoch 35, train_loss = 0.619, val_loss = 0.637\n",
            "Epoch 36, train_loss = 0.602, val_loss = 0.624\n",
            "EarlyStopping counter: 1 out of 7\n",
            "Epoch 37, train_loss = 0.586, val_loss = 0.791\n",
            "EarlyStopping counter: 2 out of 7\n",
            "Epoch 38, train_loss = 0.586, val_loss = 0.794\n",
            "EarlyStopping counter: 3 out of 7\n",
            "Epoch 39, train_loss = 0.583, val_loss = 0.723\n",
            "EarlyStopping counter: 4 out of 7\n",
            "Epoch 40, train_loss = 0.549, val_loss = 0.689\n",
            "EarlyStopping counter: 5 out of 7\n",
            "Epoch 41, train_loss = 0.550, val_loss = 0.727\n",
            "EarlyStopping counter: 6 out of 7\n",
            "Epoch 42, train_loss = 0.531, val_loss = 0.884\n",
            "EarlyStopping counter: 7 out of 7\n",
            "Save ckpt_4.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for itr in range(5):\n",
        "  state_dict = torch.load(f'cktp_{itr}.pt')\n",
        "  vgg_batchnorm_model = VGG_BatchNormTorch(in_channels=1, out_features=5).to(\"cuda\")\n",
        "  vgg_batchnorm_model.load_state_dict(state_dict)\n",
        "  preds, trues = eval(vgg_batchnorm_model, test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQ8bWf6ft8dg",
        "outputId": "5e16b7d8-7656-4f76-9f44-1660cae6449a"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 82.45614035087719%\n",
            "Test Accuracy: 78.94736842105263%\n",
            "Test Accuracy: 81.87134502923976%\n",
            "Test Accuracy: 85.38011695906432%\n",
            "Test Accuracy: 85.96491228070175%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test accuracy가 높은 3개를 가지고 와서 Ensemble을 하겠습니다.\n",
        "# Ensemble방식은 결과를 평균하겠습니다.\n",
        "\n",
        "def eval_ensemble(model_idxs, data_loader):\n",
        "  #### 실습 : 평가를 위해서는 eval()을 선언\n",
        "\n",
        "  total = 0\n",
        "  correct = 0\n",
        "\n",
        "  preds = []\n",
        "  trues = []\n",
        "  #### 실습 : Gradient를 타지 않아야 한다\n",
        "  with torch.no_grad():\n",
        "    for images, _, labels in data_loader:\n",
        "      images, labels = images.cuda(), labels.cuda()\n",
        "\n",
        "      outputs = []\n",
        "      for idx in model_idxs:\n",
        "        state_dict = torch.load(f'cktp_{itr}.pt')\n",
        "        model = VGG_BatchNormTorch(in_channels=1, out_features=5).to(\"cuda\")\n",
        "        model.load_state_dict(state_dict)\n",
        "\n",
        "        model.eval()\n",
        "        output = model(images)\n",
        "        outputs.append(output)\n",
        "\n",
        "      # Ensemble 결과를 모으고\n",
        "      outputs = torch.stack(outputs, dim=0) # 3 x 10 x 5\n",
        "\n",
        "      # 평균취한다.\n",
        "      outputs = torch.mean(outputs, dim=0) # 10 x 5\n",
        "\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "      preds.append(predicted.detach().cpu().numpy())\n",
        "      trues.append(labels.detach().cpu().numpy())\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "\n",
        "  print('Test Accuracy: {}%'.format(accuracy))\n",
        "  return preds, trues\n",
        "\n",
        "preds, trues = eval_ensemble([0,3,4], test_dataloader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hh6g2WRw2kk0",
        "outputId": "5cccbebb-1d25-4786-e0b3-62548cc7dfca"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 85.96491228070175%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_label = np.stack(preds[:-1]).flatten()\n",
        "test_labels = np.stack(trues[:-1]).flatten()\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(test_labels, prediction_label))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7vS2g5c9fpC",
        "outputId": "5b39e856-4230-4ada-8d91-2bd516021bca"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.93      0.91        92\n",
            "           1       0.91      0.80      0.85        25\n",
            "           2       0.68      0.83      0.75        18\n",
            "           3       0.67      0.67      0.67        15\n",
            "           4       1.00      0.75      0.86        20\n",
            "\n",
            "    accuracy                           0.86       170\n",
            "   macro avg       0.83      0.80      0.81       170\n",
            "weighted avg       0.87      0.86      0.86       170\n",
            "\n"
          ]
        }
      ]
    }
  ]
}